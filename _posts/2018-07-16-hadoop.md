---
title: 在MacOS上安装Hadoop的流程记录（上）
abstract: 本文简单记录在MacOS安装，配置，启动Hadoop的过程。
---

## {{ page.title }}

本文简单记录在MacOS安装，配置，启动Hadoop的过程。

首先是使用Homebrew[^1]来安装hadoop：

```bash
$ brew install hadoop
```

我在安装完成后，遇到了link error：

![]({{ site.url }}/assets/DraggedImage.e659800a28af4656b13508be735ff534.jpeg)

为了解决这个问题，我手工创建了`/usr/local/sbin`目录：

```bash
$ sudo mkdir /usr/local/sbin
$ sudo chown -R weli:staff /usr/local/sbin
```

然后重新把hadoop进行link（其实就是把hadoop的命令设置进`/usr/local/sbin`路径）：

```bash
$ brew link hadoop
Linking /usr/local/Cellar/hadoop/3.1.0... 27 symlinks created
```

需要注意的是，`/usr/local/sbin`这个路径，默认是不在可执行程序的搜索范围内的，我们需要把它添加进我们的`~/.bash_profile`里面：

```bash
$ echo 'export PATH="/usr/local/sbin:$PATH"' >> ~/.bash_profile
$ . ~/.bash_profile
```

这样，我们后续就可以直接执行hadoop的相关命令了：

```bash
$ ls /usr/local/sbin/ | grep start
start-all.sh
start-balancer.sh
start-dfs.sh
start-secure-dns.sh
start-yarn.sh
```

接下来我们可以依照官方文档[^2]当中的介绍，对安装好的hadoop进行配置。首先是格式化namenode：

```bash
$ hdfs namenode -format
```

以下是格式化完成的情况：

![]({{ site.url }}/assets/DraggedImage.15ba645b3c9f4b73b00cb749f2a33b61.jpeg)

完成这一步以后，我们要依照官方文档修改几个基础配置文件：

```bash
$ pwd
/usr/local/Cellar/hadoop/3.1.0
$ find . | grep site.xml
./libexec/etc/hadoop/core-site.xml
./libexec/etc/hadoop/hdfs-site.xml
...
```

首先是往`core-site.xml`里面添加相关配置：

```xml
<configuration>
	<configuration>
		<property>
			<name>fs.defaultFS</name>
			<value>hdfs://localhost:9000</value>
		</property>
	</configuration>
</configuration>
```

然后是往`hdfs-site.xml`里面添加配置内容：

```xml
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>
```

完成配置以后，下一个任务就是启动hdfs的文件系统。但是在启动之前，我们要配置一下本机的ssh环境。因为hdfs是通过ssh进行认证登录的，所以我们要把本机加入到自己自身服务的ssh信任列表中。

首先我们要为本机创建公钥：

```bash
  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
```

然后我们要把公钥加入到自身的信任列表里（因为我们的服务就跑在本机上面）：

```bash
  $ cat /.ssh/id_rsa.pub >> /.ssh/authorized_keys
  $ chmod 0600 ~/.ssh/authorized_keys
```

完成了以上配置以后，我们就可以启动hdfs服务了：

```bash
$ sbin/start-dfs.sh
```

以下是启动情况：

![]({{ site.url }}/assets/DraggedImage.11a2d6957f6245efb5b21591a72b4c9f.jpeg)

启动后，我们在hdfs文件系统里创建用户目录：

```bash
$ hdfs dfs -mkdir /user
$ hdfs dfs -mkdir /user/weli
```

创建完成后，可以使用命令查看创建好的目录：

```bash
$ hdfs dfs -ls /
Found 1 items
drwxr-xr-x   - weli supergroup          0 2018-07-16 11:31 /user
```

我们也可以使用`hadoop`命令来查看hdfs文件系统：

```bash
$ hadoop fs -ls hdfs:///
Found 1 items
drwxr-xr-x   - weli supergroup          0 2018-07-16 11:31 hdfs:///user
```

除了hdfs文件系统，`hadoop`命令还支持很多别的文件系统，具体列表如下[^3]：

![]({{ site.url }}/assets/766B2558-D941-40E2-95AC-58AE8F78F2E5.a445061c1f9c4e3180c5dcd5651ac62e.png)

以上是在MacOS系统上，安装，配置并启动Hadoop的一个流程。在本文的下半部分，再给大家介绍Yarn的配置和启动过程。

[^1]:	[Homebrew - The missing package manager for macOS](https://brew.sh/)

[^2]:	[Apache Hadoop 2.9.1 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)

[^3]:	[Hadoop: The Definitive Guide, 4th Edition](http://shop.oreilly.com/product/0636920033448.do)
