---
title: MacOS下面设置Solr的中文分词
abstract: 本文记录MacOS下Solr的中文分词器的配置过程。
---

## {{ page.title }}

本文记录MacOS下Solr的中文分词器的配置过程。

使用`brew`命令安装好Solr：

```bash
$ brew install solr
```

安装好以后，可以找到`solr`自带的一个`smartcn`的分词包：

```bash
$ pwd
/usr/local
$ find . | grep smartcn
./Cellar/solr/7.4.0/libexec/contrib/analysis-extras/lucene-libs/lucene-analyzers-smartcn-7.4.0.jar
```

这个是给中文做分词用的，我们把它拷贝到solr的项目目录中：

```bash
$ pwd
$ /usr/local/Cellar/solr
$ cp ./7.4.0/libexec/contrib/analysis-extras/lucene-libs/lucene-analyzers-smartcn-7.4.0.jar ./7.4.0/server/solr-webapp/webapp/WEB-INF/lib/lucene-analyzers-smartcn-7.4.0.jar
```

拷贝完分词包以后，我们启动solr：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.613e62be624d4c748640554350551bd4.jpeg)

然后创建一个新的core：

```bash
$ solr create -c foo
WARNING: Using _default configset with data driven schema functionality. NOT RECOMMENDED for production use.
		 To turn off: bin/solr config -c foo -p 8983 -action set-user-property -property update.autoCreateFields -value false
INFO  - 2018-07-22 21:26:23.679; org.apache.solr.util.configuration.SSLCredentialProviderFactory; Processing SSL Credential Provider chain: env;sysprop

Created new core 'foo'
```

启动solr并创建了foo这个core以后，我们可以打开core对应的页面：

> [http://127.0.0.1:8983/solr/#/foo](http://127.0.0.1:8983/solr/#/foo)

下面是管理端的页面状态：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.84d46b6a12874cbdb67453ad7af7517b.jpeg)

此时我们要停掉solr服务：

```bash
$ solr stop
Sending stop command to Solr running on port 8983 ... waiting up to 180 seconds to allow Jetty process 15826 to stop gracefully.
```

此时我们要查看`foo`这个core的相关配置文件：

```bash
$ ls /usr/local//Cellar/solr/7.4.0/server/solr/foo/conf/
lang           managed-schema params.json    protwords.txt  solrconfig.xml stopwords.txt  synonyms.txt
```

可以看到一个名为`managed-schema`的配置文件，这个文件里面配置了各种analyzers，我们要把上面那个smartcn的分词包配置进这个文件：

```xml
<fieldType name="text_smartcn" class="solr.TextField" positionIncrementGap="0">
	<analyzer type="index">
	  <tokenizer class="org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory"/>
	</analyzer>
	<analyzer type="query">
	   <tokenizer class="org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory"/>
	</analyzer>
</fieldType>
```

上面这段添加到这个`CJK`的fieldtype配置下面就可以了：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.8ab4674b611c4d13a33d6255618c0ce6.jpeg)

这样我们就配置好了中文分词器。接下来就是重新启动solr：

```bash
$ solr start
```

服务启动完成后，我们回到solr的管理页面，选择`foo`这个core，然后进入analysis页面：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.490f8dc5cdbe4ccc8f36945f8a5eb35b.jpeg)

然后我们输入一段中文，再使用配置好的`text_smartcn`分析器：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.80d67083767047eeab1bc90c4f7bb8c3.jpeg)

设置完成后，点击"Analyse Values"，我们就可以看到分词的结果了：

![](https://raw.githubusercontent.com/liweinan/blogpicbackup/master/data/DraggedImage.3923b15394e4441a81cdd4b75dca8861.jpeg)

这样，Solr就可以对中文进行分词了，从而支持对中文词汇的检索。

