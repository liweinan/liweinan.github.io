---
title: 在MacOS上安装Hadoop的流程记录（下）
abstract: 本文简单记录在MacOS安装，配置，启动Hadoop的过程。本文是下篇，主要介绍Yarn的配置和启动，以及执行MapReduce任务的方法。
---

## {{ page.title }}

本文简单记录在MacOS安装，配置，启动Hadoop的过程。本文是下篇，主要介绍Yarn的配置和启动，以及执行MapReduce任务的方法。

在上篇的基础上，我们继续配置`yarn-site.xml`：

```xml
<configuration>

	<!-- Site specific YARN configuration properties -->
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>localhost</value>
	</property>
</configuration>
```

上面的配置指定了resource manager为localhost。

配置完成后，我们先使用`start-dfs.sh`来启动hdfs：

![]({{ site.url }}/assets/DraggedImage.cc8ad55272954804a1540559e050df52.jpeg)

仔细观察这个启动过程，可以看到实际上有三部分组件被启动了，分别是`namenodes`，`datanodes`，`secondary namenodes`。其中`namenodes`主要是用来管理hdfs里面的数据metadata，而`datanodes`用于实际的数据存储。关于`secondary namenodes`的用途，可以查看这篇文档：

> [Secondary Namenode - What it really do?](http://blog.madhukaraphatak.com/secondary-namenode---what-it-really-do/)

以下是hdfs的一个架构图：

![]({{ site.url }}/assets/DraggedImage.1560c945761c4cc39b10fb4296e3def4.jpeg)
（图片来源：[Hadoop: The Definitive Guide, 4th Edition](http://shop.oreilly.com/product/0636920033448.do)）

整个架构是分布式的，各个模块可以分散部署，也可以像我们这个文档里面说明的这样，集中部署在一台机器上面。

hdfs启动以后，我们使用`start-yarn.sh`来启动Yarn服务：

![]({{ site.url }}/assets/DraggedImage.8cc1671400a743a8b9dd083424f4d558.jpeg)

可以看到Yarn包含两个组件，分别是`resourcemanager`和`nodemanagers`。

以下是Yarn的架构图：

![]({{ site.url }}/assets/DraggedImage.fae75fd318184d63871a65e69ec78998.jpeg)
（图片来源：[Hadoop: The Definitive Guide, 4th Edition](http://shop.oreilly.com/product/0636920033448.do)）

可以看到Yarn是如何通过`ResourceManager`来提交map reduce任务的。

以上的启动过程完成后，我们可以查看hadoop的实际文件结构。Hadoop默认是在`/tmp`目录下保存文件，目录名称是`用户名 + hadoop`的格式。下面是我机器上的数据：

![]({{ site.url }}/assets/DraggedImage.587ba93a224645ce8abdf7fc85024661.jpeg)

可以看到出了一些pid进程文件以外，还有`hadoop-weli`这个数据目录。以下是目录中的内容：

![]({{ site.url }}/assets/DraggedImage.b0d83eb7023640b38abbb229acab944f.jpeg)

从上面的图可以看到各个模块生成的初始数据。

接下来我们可以试着提交一个map reduce的任务：

```bash
$ pwd
/usr/local/Cellar/hadoop/3.1.0/libexec/share/hadoop/mapreduce
$ yarn jar ./hadoop-mapreduce-examples-3.1.0.jar pi 16 1000
```

上面的这个`hadoop-mapreduce-examples-3.1.0.jar`是hadoop自带的例子，我们把它通过`yarn`命令进行提交，用它来跑一个运算Pi的数值的map reduce任务。

以下是任务的运行情况：

![]({{ site.url }}/assets/d18b0bdc00bcfde6c1d94b93f97997fc.gif)

上面的任务执行结果如下：

```
Job Finished in 2.733 seconds
Estimated value of Pi is 3.14250000000000000000
```

如果你对上面这个例子的源代码感兴趣，可以在这里查看源码：

> [https://github.com/c9n/hadoop/tree/master/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/pi](https://github.com/c9n/hadoop/tree/master/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/pi)

在上面的任务执行完成后，我们可以重新查看`/tmp`中hadoop的文件数据的变化：

![]({{ site.url }}/assets/DraggedImage.fd097898d32a4069a412a02c9211b800.jpeg)

可以看到多了一个`mapred`目录，里面有我们这次任务（job）的执行日志。

以上就是Yarn的配置，以及mapreduce任务的执行过程。本文虽然是下篇，但是这两篇文章加起来，只是对hadoop的一个初步体会。后续我还会继续写文章介绍如何撰写一个mapreduce任务，以及围绕着hadoop的各种工具的使用。

